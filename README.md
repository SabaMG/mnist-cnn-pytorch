# ğŸ§  MNIST Handwritten Digit Classifier (PyTorch)

This project implements a high-accuracy digit classification model on the MNIST dataset using modern deep learning techniques in **PyTorch**.

> ğŸ¯ Final test accuracy: **99.48%** (with data augmentation + CNN + regularization)

---

## ğŸš€ Features

- âœ… Convolutional Neural Network (CNN) for image classification  
- âœ… Batch Normalization and Dropout for regularization  
- âœ… Data Augmentation for improved generalization  
- âœ… Training reproducibility with fixed random seeds  
- âœ… Best-model saving during training (checkpointing)  
- âœ… MPS backend support for Apple Silicon (e.g., M3 Max)

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ data/               # MNIST dataset (auto-downloaded)
â”œâ”€â”€ main.py             # Main training & evaluation logic
â”œâ”€â”€ model.py            # CNN architecture with batchnorm & dropout
â”œâ”€â”€ utils.py            # Helpers (e.g., seed setting, model save/load)
â”œâ”€â”€ best_model.pth      # Saved weights of the best model (optional)
â””â”€â”€ README.md
```

---

## ğŸ§ª Quickstart

### 1. Clone and create virtual environment

```bash
git clone https://github.com/SabaMG/mnist-cnn-pytorch.git
cd mnist-cnn-pytorch
python3 -m venv .venv
source .venv/bin/activate  # or .venv\Scripts\activate on Windows
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

### 3. Train the model

```bash
python main.py
```

The best model is saved automatically as `best_model.pth`.

---

## ğŸ§¾ Results

| Epochs | Accuracy | Loss     |
|--------|----------|----------|
| 30     | 99.48%   | ~45      |

Trained with:
- CNN (2 conv layers + 2 FC layers)
- Dropout 0.3
- BatchNorm
- AdamW optimizer
- Seeded runs
- Data augmentation (rotation, affine shift)

---

## ğŸ› ï¸ Dependencies

- Python 3.8+
- torch
- torchvision
- numpy
- matplotlib (optional for plotting)

---

## ğŸ“Œ Notes

- Tested on macOS with Apple Silicon (`mps` backend)
- You can tweak the model or try other datasets like `FashionMNIST` or `CIFAR10` to go further

---

## ğŸªª License

MIT License