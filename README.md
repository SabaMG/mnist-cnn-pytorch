# ğŸ§  MNIST Handwritten Digit Classifier (PyTorch)

This project implements a high-accuracy digit classification model on the MNIST dataset using modern deep learning techniques in **PyTorch**.

> ğŸ¯ Final test accuracy: **99.59%** (with 4-layer CNN + data augmentation + regularization)

---

## ğŸš€ Features

- âœ… Convolutional Neural Network (CNN) for image classification  
- âœ… Batch Normalization and Dropout for regularization  
- âœ… Data Augmentation for improved generalization  
- âœ… Training reproducibility with fixed random seeds  
- âœ… Best-model saving during training (checkpointing)  
- âœ… TensorBoard logging for metrics and visualizations  
- âœ… MPS backend support for Apple Silicon (e.g., M3 Max)

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ data/               # MNIST dataset (auto-downloaded)
â”œâ”€â”€ model.py            # CNN architecture
â”œâ”€â”€ train.py            # Training loop
â”œâ”€â”€ evaluate.py         # Evaluation logic
â”œâ”€â”€ dataset.py          # Data loading and transforms
â”œâ”€â”€ utils.py            # Helpers (seed, weight init, etc.)
â”œâ”€â”€ config.py           # Configs (device, paths, etc.)
â”œâ”€â”€ main.py             # Main launcher
â”œâ”€â”€ requirements.txt    # Dependencies
â”œâ”€â”€ best_model.pth      # (optional) Best saved model
â”œâ”€â”€ runs/               # TensorBoard logs
â””â”€â”€ README.md
```

---

## ğŸ§ª Quickstart

### 1. Clone and create virtual environment

```bash
git clone https://github.com/SabaMG/mnist-cnn-pytorch.git
cd mnist-cnn-pytorch
python3 -m venv .venv
source .venv/bin/activate  # or .venv\Scripts\activate on Windows
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

### 3. Train the model

```bash
python main.py
```

The best model will be saved automatically as `best_model.pth`.

### 4. Launch TensorBoard (optional)

```bash
tensorboard --logdir=runs
```

Then open [http://localhost:6006](http://localhost:6006) in your browser.

---

## ğŸ“Š Model Comparison (Architectures)

| Model Name           | Conv Layers | Pooling Strategy     | Final Accuracy | Max Accuracy | Training Time (approx.) | Notes                                      |
|----------------------|-------------|-----------------------|----------------|--------------|--------------------------|--------------------------------------------|
| `mnist_cnn_baseline` | 2           | MaxPool               | 99.41%         | 99.48%       | â˜…â˜…â˜…â˜†â˜†                   | Baseline simple, robuste et efficace       |
| `cnn_v1_deep_3conv`  | 3           | MaxPool               | **99.48%**         | **99.58%**       | â˜…â˜…â˜…â˜…â˜†                   | Meilleure performance globale              |
| `cnn_v2_deep_3conv`  | 3           | MaxPool               | 99.45%         | 99.55%       | â˜…â˜…â˜…â˜…â˜†                   | TrÃ¨s proche du meilleur, stable            |
| `CNN_3Conv_Stride`   | 3           | Strided Convolutions  | 99.38%         | 99.48%       | â˜…â˜…â˜†â˜†â˜†                   | Le plus rapide Ã  entraÃ®ner                 |
| `CNN_4Conv`          | 4           | MaxPool               | 99.59%         | 99.59%       | â˜…â˜…â˜…â˜…â˜…                   | Lourd, long Ã  entraÃ®ner mais performant    |

> ğŸ§ª *Training time scale:*  
> â˜…â˜†â˜†â˜†â˜† = very fast â€” â˜…â˜…â˜…â˜…â˜… = long training

---

## ğŸ“ˆ Final Results

| Epochs | Accuracy | Loss     |
|--------|----------|----------|
| 30     | **99.58%**   | ~42      |

Trained with:
- CNN (up to 3 convolutional layers)
- Dropout 0.3
- Batch Normalization
- AdamW optimizer
- Data augmentation: rotation + affine shift
- Early stopping + best model checkpoint
- Reproducibility: fixed random seed
- TensorBoard visual logging

---

## ğŸ› ï¸ Dependencies

- Python 3.11
- torch
- torchvision
- numpy
- matplotlib *(optional)*
- tensorboard *(optional)*

---

## ğŸ“Œ Notes

- Optimized for macOS with Apple Silicon (`mps` backend), but works on CPU and CUDA as well.
- You can switch model versions by editing the architecture inside `model.py`.

---

## ğŸªª License

MIT License